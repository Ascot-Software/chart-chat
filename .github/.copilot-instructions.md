# GitHub Copilot Instructions for Data Formulator

## Project Overview

Data Formulator is an AI-powered data visualization tool that combines user interface interactions with natural language inputs for creating rich visualizations. The project is a full-stack application with a React/TypeScript frontend and Python/Flask backend.

## Architecture & Technology Stack

### Frontend (React/TypeScript)
- **Framework**: React 18 with TypeScript
- **State Management**: Redux Toolkit
- **UI Library**: Material-UI (MUI)
- **Visualization**: Vega-Lite, D3.js
- **Build Tool**: Vite
- **Styling**: SCSS with Material-UI theming

### Backend (Python/Flask)
- **Framework**: Flask with blueprints
- **Database**: DuckDB for local analytics
- **AI Integration**: LiteLLM supporting OpenAI, Azure, Anthropic, Ollama
- **Data Processing**: Pandas for transformations
- **External Data**: Connectors for MySQL, PostgreSQL, Azure, S3

## Code Style & Patterns

### TypeScript/React Conventions
```typescript
// Use functional components with hooks
const ComponentName: FC<ComponentProps> = ({ prop1, prop2 }) => {
    const dispatch = useDispatch<AppDispatch>();
    const stateValue = useSelector((state: DataFormulatorState) => state.property);
    
    // Prefer explicit typing over 'any'
    const handleAction = useCallback((data: SpecificType) => {
        dispatch(dfActions.actionName(data));
    }, [dispatch]);
    
    return (
        <Box sx={{ /* Material-UI sx prop for styling */ }}>
            {/* Component content */}
        </Box>
    );
};
```

### Python/Flask Conventions
```python
# Use blueprints for route organization
@blueprint_name.route('/api-endpoint', methods=['POST'])
def endpoint_name():
    if request.is_json:
        content = request.get_json()
        
        # Validate input
        if not validate_input(content):
            return jsonify({"status": "error", "message": "Invalid input"}), 400
        
        try:
            # Process request
            result = process_data(content)
            return jsonify({"status": "ok", "result": result})
        except Exception as e:
            logger.error(f"Error in endpoint: {str(e)}")
            return jsonify({"status": "error", "message": str(e)}), 500
    
    return jsonify({"status": "error", "message": "JSON required"}), 400
```

## AI Agent Pattern

When creating new AI agents, follow this pattern:

```python
class NewAgent(object):
    def __init__(self, client, system_prompt=None, **kwargs):
        self.client = client
        self.system_prompt = system_prompt or DEFAULT_SYSTEM_PROMPT
        # Additional configuration
    
    def run(self, input_data, **params):
        # Prepare data summary
        data_summary = generate_data_summary(input_data)
        
        # Construct messages
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": f"[CONTEXT]\n{data_summary}\n[GOAL]\n{params}\n[OUTPUT]\n"}
        ]
        
        # Get LLM response
        response = self.client.get_completion(messages=messages)
        
        # Process and return results
        return self.process_response(response, messages)
    
    def process_response(self, response, messages):
        candidates = []
        for choice in response.choices:
            # Extract code/JSON from response
            # Execute if needed
            # Format result
            candidates.append(result)
        return candidates
```

## Data Visualization Patterns

### Chart Creation
```typescript
// Use the chart template system
const chartTemplate = getChartTemplate(chartType);
const assembledChart = assembleVegaChart(
    chartType,
    encodingMap,
    conceptShelfItems,
    tableRows,
    width,
    height
);

// Embed with Vega
embed('#chart-element-id', assembledChart, {
    actions: false,
    renderer: "canvas"
});
```

### Encoding Management
```typescript
// Update chart encodings through Redux
dispatch(dfActions.updateChartEncoding({
    chartId,
    channel: 'x', // or 'y', 'color', etc.
    encoding: {
        fieldID: field.id,
        aggregate: 'sum',
        sortOrder: 'ascending'
    }
}));
```

## Database Patterns

### DuckDB Operations
```python
# Always use parameterized queries for safety
def execute_sql_safely(conn, query, params=None):
    try:
        if params:
            result = conn.execute(query, params).fetch_df()
        else:
            result = conn.execute(query).fetch_df()
        return result
    except Exception as e:
        logger.error(f"SQL execution error: {str(e)}")
        raise

# Create temporary views for data transformations
table_name = f"view_{random_suffix}"
create_query = f"CREATE VIEW IF NOT EXISTS {table_name} AS {user_query}"
conn.execute(create_query)
```

## Security Best Practices

### Input Validation
```python
def sanitize_table_name(name):
    # Remove special characters, limit length
    import re
    name = re.sub(r'[^a-zA-Z0-9_]', '_', name)
    return name[:50]  # Limit length

def validate_sql_query(query):
    # Check for dangerous operations
    dangerous_keywords = ['DROP', 'DELETE', 'INSERT', 'UPDATE', 'ALTER']
    query_upper = query.upper()
    for keyword in dangerous_keywords:
        if keyword in query_upper:
            raise ValueError(f"Dangerous SQL operation: {keyword}")
```

### API Security
```python
# Always validate API inputs
def validate_model_config(config):
    required_fields = ['endpoint', 'model']
    for field in required_fields:
        if field not in config:
            raise ValueError(f"Missing required field: {field}")
    
    # Sanitize API keys in logs
    safe_config = {k: v if k != 'api_key' else '***' for k, v in config.items()}
    logger.info(f"Model config: {safe_config}")
```

## Error Handling Patterns

### Frontend Error Handling
```typescript
// Use try-catch with user-friendly messages
const handleApiCall = async (data: RequestData) => {
    try {
        const response = await fetch('/api/endpoint', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(data)
        });
        
        if (!response.ok) {
            throw new Error(`API error: ${response.status}`);
        }
        
        const result = await response.json();
        return result;
    } catch (error) {
        dispatch(dfActions.addMessages({
            timestamp: Date.now(),
            component: "api",
            type: "error",
            value: `Operation failed: ${error.message}`
        }));
        throw error;
    }
};
```

### Backend Error Handling
```python
def handle_agent_errors(func):
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            logger.error(f"Agent error in {func.__name__}: {str(e)}")
            return [{
                'status': 'error',
                'content': f"Agent execution failed: {str(e)}",
                'code': ''
            }]
    return wrapper
```

## Performance Considerations

### Data Handling
```python
# Limit data size for performance
MAX_ROWS = 5000
if len(data) > MAX_ROWS:
    data = data.sample(n=MAX_ROWS)
    logger.warning(f"Data truncated to {MAX_ROWS} rows")

# Use streaming for large datasets
def process_large_dataset(data_iterator):
    for chunk in data_iterator:
        yield process_chunk(chunk)
```

### Frontend Optimization
```typescript
// Use React.memo for expensive components
const ExpensiveChart = React.memo(({ chart, data }) => {
    return <VegaLite spec={chart} data={data} />;
}, (prevProps, nextProps) => {
    // Custom comparison for when to re-render
    return prevProps.chart.id === nextProps.chart.id &&
           prevProps.data.length === nextProps.data.length;
});
```

## Testing Patterns

### Frontend Testing
```typescript
// Test Redux actions and selectors
describe('dfSlice', () => {
    it('should update chart encoding', () => {
        const initialState = createInitialState();
        const action = dfActions.updateChartEncoding({
            chartId: 'chart-1',
            channel: 'x',
            encoding: { fieldID: 'field-1' }
        });
        const newState = dfSlice.reducer(initialState, action);
        // Assertions
    });
});
```

### Backend Testing
```python
# Test API endpoints
def test_derive_data_endpoint():
    with app.test_client() as client:
        response = client.post('/api/derive-data', json={
            'token': 'test',
            'model': test_model_config,
            'input_tables': test_data,
            'new_fields': ['field1'],
            'extra_prompt': 'test prompt'
        })
        assert response.status_code == 200
        assert response.json['status'] == 'ok'
```

## File Organization Guidelines

### Frontend Structure
```
src/
├── app/           # Redux store, main app logic
├── components/    # Reusable UI components
├── views/         # Page-level components
├── data/          # Data models and utilities
├── scss/          # Styling files
└── assets/        # Static assets
```

### Backend Structure
```
py-src/data_formulator/
├── agents/        # AI agents for different tasks
├── data_loader/   # External data connectors
├── app.py         # Main Flask application
├── *_routes.py    # Route handlers by feature
└── *.py           # Utility modules
```

## Common Issues to Avoid

1. **Memory Leaks**: Always clean up Vega-Lite chart instances
2. **SQL Injection**: Use parameterized queries, validate table names
3. **API Key Exposure**: Never log or return API keys
4. **State Mutations**: Use immutable updates in Redux
5. **Error Swallowing**: Always log and handle errors appropriately
6. **Resource Cleanup**: Close database connections, clean temporary files

## Integration Points

### Frontend ↔ Backend Communication
- Use `/api/` prefix for all backend endpoints
- Include session ID in requests for stateful operations
- Handle loading states and errors consistently
- Use Server-Sent Events for real-time updates

### AI Model Integration
- Always validate model configurations before use
- Implement retry logic for transient failures
- Cache responses when appropriate
- Sanitize inputs to prevent prompt injection

This instruction file should help Copilot understand the project structure, coding patterns, and best practices when suggesting code for the Data Formulator project.
